{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNW8tSHcrhZ1pV/wqpu7zSW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejashreereddyy/FMML-Project-and-Labs/blob/main/Copy_of_AIML_III_Module_01_Lab_02_Machine_Learning_terms_and_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h0HdTIwT62ki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Machine Learning terms and metrics\n",
        "\n",
        "Module 1, Lab 2\n",
        "\n",
        "In this lab, we will show a part of the ML pipeline by using the California Housing dataset. There are 20640 samples, each with 8 attributes like income of the block, age of the houses per district etc. The task is to predict the cost of the houses per district. We will use the scikit-learn library to load the data and perform some basic data preprocessing and model training. We will also show how to evaluate the model using some common metrics, split the data into training and testing sets, and use cross-validation to get a better estimate of the model's performance."
      ],
      "metadata": {
        "id": "w3RORnzc680x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Step 1: Getting the Data\n",
        "# Load the California Housing dataset\n",
        "california = fetch_california_housing()\n",
        "\n",
        "# Create a DataFrame with the data\n",
        "data = pd.DataFrame(california.data, columns=california.feature_names)\n",
        "data['MedHouseVal'] = california.target\n",
        "\n",
        "# Display the top 5 rows of data\n",
        "print(\"Top 5 rows of data:\")\n",
        "print(data.head())\n",
        "\n",
        "# Step 2: Preparing the Data\n",
        "# Split the data into features (X) and target (y)\n",
        "X = data.drop('MedHouseVal', axis=1)\n",
        "y = data['MedHouseVal']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Teaching the Toy (Training the Model)\n",
        "# Create a Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model using the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Checking How Well the Toy Learned (Evaluating the Model)\n",
        "# Predict the prices using the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Calculate the R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared Score: {r2}\")\n",
        "\n",
        "# Step 5: Cross-Validation\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Calculate the mean of the cross-validation scores\n",
        "mean_cv_score = np.mean(cv_scores)\n",
        "\n",
        "print(f\"Cross-Validation Mean Squared Error: {-mean_cv_score}\")\n"
      ],
      "metadata": {
        "id": "nE7kRKcx7ISk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Data: We fetch the California Housing dataset and create a DataFrame to see the first 5 rows of data.\n",
        "\n",
        "Preparing the Data: We split the data into features (information about the houses) and the target (house prices). Then, we split this into training and testing sets.\n",
        "\n",
        "Training the Model: We create a Linear Regression model and teach it using the training data.\n",
        "\n",
        "Evaluating the Model: We make the model guess the house prices using the testing data and check how good the guesses are using mean squared error and R-squared score.\n",
        "\n",
        "Cross-Validation: We use cross-validation to get a better estimate of the model's performance by splitting the data into different parts and checking the model's performance on each part."
      ],
      "metadata": {
        "id": "6xKYvJ_e7Nuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simplest model to use for classification is the K-Nearest Neighbors model. We will use this model to predict the house value with a K value of 1. We will also use the accuracy metric to evaluate the model."
      ],
      "metadata": {
        "id": "DcJ3wpy77iS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load and Prepare the Data\n",
        "# Load the California Housing dataset\n",
        "california = fetch_california_housing()\n",
        "\n",
        "# Create a DataFrame with the data\n",
        "data = pd.DataFrame(california.data, columns=california.feature_names)\n",
        "data['MedHouseVal'] = california.target\n",
        "\n",
        "# Convert the target variable into categories\n",
        "# Let's create 3 categories for simplicity: Low, Medium, High\n",
        "data['MedHouseValCat'] = pd.qcut(data['MedHouseVal'], 3, labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "# Display the top 5 rows of data\n",
        "print(\"Top 5 rows of data:\")\n",
        "print(data.head())\n",
        "\n",
        "# Step 2: Split the Data\n",
        "# Split the data into features (X) and target (y)\n",
        "X = data.drop(['MedHouseVal', 'MedHouseValCat'], axis=1)\n",
        "y = data['MedHouseValCat']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the KNN Model\n",
        "# Create a KNN model with K=1\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "# Train the model using the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate the Model\n",
        "# Predict the categories using the testing data\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "dUFr5ofq7jH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3wwcZOHhDc14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does averaging the validation accuracy across multiple splits give more consistent results?\n",
        "\n",
        "Yes, averaging the validation accuracy across multiple splits (cross-validation) gives more consistent results. It reduces the variability that might result from a single train-test split.\n",
        "\n",
        "Does it give a more accurate estimate of test accuracy?\n",
        "\n",
        "Yes, cross-validation provides a more accurate estimate of the model's performance on unseen data because it ensures that every data point gets a chance to be in the training and testing sets, thus reducing the risk of overfitting to a particular train-test split.\n",
        "\n",
        "What is the effect of the number of iterations on the estimate? Do we get a better estimate with higher iterations?\n",
        "\n",
        "Generally, a higher number of iterations (folds) in cross-validation can give a better estimate, as it provides more samples for the training and testing processes, leading to a more reliable estimate. However, it also increases computational complexity.\n",
        "\n",
        "Can we deal with a very small train dataset or validation dataset by increasing the iterations?\n",
        "\n",
        "Increasing the number of iterations in cross-validation can help mitigate issues with small datasets by ensuring that each data point is used for both training and validation multiple times. However, if the dataset is very small, this might not fully resolve the problem, and other techniques like data augmentation or using simpler models might be necessary.\n",
        "\n",
        "How does the accuracy of the 3 nearest neighbor classifier change with the number of splits? How is it affected by the split size? Compare the results with the 1 nearest neighbor classifier.\n",
        "\n",
        "To analyze this, we'll write a Python script to perform the necessary experiments."
      ],
      "metadata": {
        "id": "Ufj9pyDwEcEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the California Housing dataset\n",
        "california = fetch_california_housing()\n",
        "\n",
        "# Create a DataFrame with the data\n",
        "data = pd.DataFrame(california.data, columns=california.feature_names)\n",
        "data['MedHouseVal'] = california.target\n",
        "\n",
        "# Convert the target variable into categories\n",
        "data['MedHouseValCat'] = pd.qcut(data['MedHouseVal'], 3, labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "# Prepare features (X) and target (y)\n",
        "X = data.drop(['MedHouseVal', 'MedHouseValCat'], axis=1)\n",
        "y = data['MedHouseValCat']\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define a function to perform cross-validation with different K and splits\n",
        "def cross_val_knn(k, n_splits):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    scores = cross_val_score(knn, X_scaled, y, cv=kf, scoring='accuracy')\n",
        "    return scores\n",
        "\n",
        "# Experiment with different K values and number of splits\n",
        "results = {}\n",
        "for k in [1, 3]:\n",
        "    for n_splits in [5, 10, 20]:\n",
        "        scores = cross_val_knn(k, n_splits)\n",
        "        results[(k, n_splits)] = {\n",
        "            'mean_accuracy': np.mean(scores),\n",
        "            'std_accuracy': np.std(scores)\n",
        "        }\n",
        "\n",
        "# Print the results\n",
        "for key, value in results.items():\n",
        "    k, n_splits = key\n",
        "    print(f\"K: {k}, Splits: {n_splits} - Mean Accuracy: {value['mean_accuracy']:.4f}, Std Dev: {value['std_accuracy']:.4f}\")\n",
        "\n",
        "# Plotting the results for better visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ks = [1, 3]\n",
        "splits = [5, 10, 20]\n",
        "accuracies = [[results[(k, s)]['mean_accuracy'] for s in splits] for k in ks]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i, k in enumerate(ks):\n",
        "    plt.plot(splits, accuracies[i], marker='o', label=f'K={k}')\n",
        "\n",
        "plt.xlabel('Number of Splits')\n",
        "plt.ylabel('Mean Accuracy')\n",
        "plt.title('Accuracy of K-Nearest Neighbors Classifier')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tQSNHYgSFbJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of Results\n",
        "Impact of Number of Splits on Accuracy: Increasing the number of splits generally provides a more reliable estimate of the model's accuracy by reducing the variance caused by any single train-test split.\n",
        "\n",
        "Comparison of K=1 and K=3:\n",
        "\n",
        "K=1 (1-Nearest Neighbor): This classifier might have higher variance because it is highly sensitive to the noise in the data. It typically has lower bias but higher variance.\n",
        "\n",
        "K=3 (3-Nearest Neighbors): This classifier tends to be more robust as it considers more neighbors. It balances bias and variance better compared to K=1, often resulting in more stable accuracy across different splits.\n",
        "\n",
        "Effect of Split Size: As the number of splits increases, each model gets trained and tested on a larger variety of data combinations, leading to more stable and consistent performance estimates. However, too many splits can increase computation time significantly.\n",
        "\n",
        "Small Train/Validation Dataset: With very small datasets, increasing the number of splits helps but does not completely solve the problem. The estimates become more stable, but the fundamental issue of limited data might still hinder the model's ability to generalize.\n",
        "\n",
        "By running the provided code, you can see how the accuracy of the 1-Nearest Neighbor and 3-Nearest Neighbor classifiers changes with different numbers of splits and compare their performance."
      ],
      "metadata": {
        "id": "tQwZySnuFhjF"
      }
    }
  ]
}